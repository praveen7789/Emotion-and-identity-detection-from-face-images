{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import dlib\n",
    "import cv2\n",
    "import pickle\n",
    "import random\n",
    "import facevec\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from imutils import face_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_gamma(input_image, gamma=1.0):\n",
    "    table = np.array([((iteration / 255.0) ** (1.0 / gamma)) * 255\n",
    "                      for iteration in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(input_image, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path, gamma=0.75):\n",
    "    output = cv2.imread(path)\n",
    "    return adjust_gamma(output, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_vector(input_image):\n",
    "    faces = facevec.detector(input_image, 1) \n",
    "    if not faces:\n",
    "        return None\n",
    "\n",
    "    f = faces[0]\n",
    "    shape = facevec.predictor(input_image, f)\n",
    "    face_descriptor = facevec.face_model.compute_face_descriptor(input_image, shape)\n",
    "    return face_descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "male = 0\n",
    "female = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving Male images ...\n",
      "Retrieved 122 faces !\n",
      "Retrieving female images ...\n",
      "Retrieved 127 faces !\n"
     ]
    }
   ],
   "source": [
    "print(\"Retrieving Male images ...\")\n",
    "sub1 = glob.glob(\"./male/*.jpeg\")\n",
    "print(\"Retrieved {} faces !\".format(len(sub1)))\n",
    "\n",
    "print(\"Retrieving female images ...\")\n",
    "sub2 = glob.glob(\"./female/*.jpeg\")\n",
    "print(\"Retrieved {} faces !\".format(len(sub2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = dlib.vectors()\n",
    "labels = dlib.array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Males images ...\n",
      "Reading 0 of 122\n",
      "Reading 1 of 122\n",
      "Reading 2 of 122\n",
      "Reading 3 of 122\n",
      "Reading 4 of 122\n",
      "Reading 5 of 122\n",
      "Reading 6 of 122\n",
      "Reading 7 of 122\n",
      "Reading 8 of 122\n",
      "Reading 9 of 122\n",
      "Reading 10 of 122\n",
      "Reading 11 of 122\n",
      "Reading 12 of 122\n",
      "Reading 13 of 122\n",
      "Reading 14 of 122\n",
      "Reading 15 of 122\n",
      "Reading 16 of 122\n",
      "Reading 17 of 122\n",
      "Reading 18 of 122\n",
      "Reading 19 of 122\n",
      "Reading 20 of 122\n",
      "Reading 21 of 122\n",
      "Reading 22 of 122\n",
      "Reading 23 of 122\n",
      "Reading 24 of 122\n",
      "Reading 25 of 122\n",
      "Reading 26 of 122\n",
      "Reading 27 of 122\n",
      "Reading 28 of 122\n",
      "Reading 29 of 122\n",
      "Reading 30 of 122\n",
      "Reading 31 of 122\n",
      "Reading 32 of 122\n",
      "Reading 33 of 122\n",
      "Reading 34 of 122\n",
      "Reading 35 of 122\n",
      "Reading 36 of 122\n",
      "Reading 37 of 122\n",
      "Reading 38 of 122\n",
      "Reading 39 of 122\n",
      "Reading 40 of 122\n",
      "Reading 41 of 122\n",
      "Reading 42 of 122\n",
      "Reading 43 of 122\n",
      "Reading 44 of 122\n",
      "Reading 45 of 122\n",
      "Reading 46 of 122\n",
      "Reading 47 of 122\n",
      "Reading 48 of 122\n",
      "Reading 49 of 122\n",
      "Reading 50 of 122\n",
      "Reading 51 of 122\n",
      "Reading 52 of 122\n",
      "Reading 53 of 122\n",
      "Reading 54 of 122\n",
      "Reading 55 of 122\n",
      "Reading 56 of 122\n",
      "Reading 57 of 122\n",
      "Reading 58 of 122\n",
      "Reading 59 of 122\n",
      "Reading 60 of 122\n",
      "Reading 61 of 122\n",
      "Reading 62 of 122\n",
      "Reading 63 of 122\n",
      "Reading 64 of 122\n",
      "Reading 65 of 122\n",
      "Reading 66 of 122\n",
      "Reading 67 of 122\n",
      "Reading 68 of 122\n",
      "Reading 69 of 122\n",
      "Reading 70 of 122\n",
      "Reading 71 of 122\n",
      "Reading 72 of 122\n",
      "Reading 73 of 122\n",
      "Reading 74 of 122\n",
      "Reading 75 of 122\n",
      "Reading 76 of 122\n",
      "Reading 77 of 122\n",
      "Reading 78 of 122\n",
      "Reading 79 of 122\n",
      "Reading 80 of 122\n",
      "Reading 81 of 122\n",
      "Reading 82 of 122\n",
      "Reading 83 of 122\n",
      "Reading 84 of 122\n",
      "Reading 85 of 122\n",
      "Reading 86 of 122\n",
      "Reading 87 of 122\n",
      "Reading 88 of 122\n",
      "Reading 89 of 122\n",
      "Reading 90 of 122\n",
      "Reading 91 of 122\n",
      "Reading 92 of 122\n",
      "Reading 93 of 122\n",
      "Reading 94 of 122\n",
      "Reading 95 of 122\n",
      "Reading 96 of 122\n",
      "Reading 97 of 122\n",
      "Reading 98 of 122\n",
      "Reading 99 of 122\n",
      "Reading 100 of 122\n",
      "Reading 101 of 122\n",
      "Reading 102 of 122\n",
      "Reading 103 of 122\n",
      "Reading 104 of 122\n",
      "Reading 105 of 122\n",
      "Reading 106 of 122\n",
      "Reading 107 of 122\n",
      "Reading 108 of 122\n",
      "Reading 109 of 122\n",
      "Reading 110 of 122\n",
      "Reading 111 of 122\n",
      "Reading 112 of 122\n",
      "Reading 113 of 122\n",
      "Reading 114 of 122\n",
      "Reading 115 of 122\n",
      "Reading 116 of 122\n",
      "Reading 117 of 122\n",
      "Reading 118 of 122\n",
      "Reading 119 of 122\n",
      "Reading 120 of 122\n",
      "Reading 121 of 122\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading Males images ...\")\n",
    "for i, sub in enumerate(sub1):\n",
    "    print(\"Reading {} of {}\\r\".format(i, len(sub1)))\n",
    "    face_vectors = face_vector(read_image(sub))\n",
    "    if face_vectors is None:\n",
    "        continue\n",
    "    vectors.append(dlib.vector(face_vectors))\n",
    "    labels.append(male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Female  images ...\n",
      "Reading 0 of 127\n",
      "Reading 1 of 127\n",
      "Reading 2 of 127\n",
      "Reading 3 of 127\n",
      "Reading 4 of 127\n",
      "Reading 5 of 127\n",
      "Reading 6 of 127\n",
      "Reading 7 of 127\n",
      "Reading 8 of 127\n",
      "Reading 9 of 127\n",
      "Reading 10 of 127\n",
      "Reading 11 of 127\n",
      "Reading 12 of 127\n",
      "Reading 13 of 127\n",
      "Reading 14 of 127\n",
      "Reading 15 of 127\n",
      "Reading 16 of 127\n",
      "Reading 17 of 127\n",
      "Reading 18 of 127\n",
      "Reading 19 of 127\n",
      "Reading 20 of 127\n",
      "Reading 21 of 127\n",
      "Reading 22 of 127\n",
      "Reading 23 of 127\n",
      "Reading 24 of 127\n",
      "Reading 25 of 127\n",
      "Reading 26 of 127\n",
      "Reading 27 of 127\n",
      "Reading 28 of 127\n",
      "Reading 29 of 127\n",
      "Reading 30 of 127\n",
      "Reading 31 of 127\n",
      "Reading 32 of 127\n",
      "Reading 33 of 127\n",
      "Reading 34 of 127\n",
      "Reading 35 of 127\n",
      "Reading 36 of 127\n",
      "Reading 37 of 127\n",
      "Reading 38 of 127\n",
      "Reading 39 of 127\n",
      "Reading 40 of 127\n",
      "Reading 41 of 127\n",
      "Reading 42 of 127\n",
      "Reading 43 of 127\n",
      "Reading 44 of 127\n",
      "Reading 45 of 127\n",
      "Reading 46 of 127\n",
      "Reading 47 of 127\n",
      "Reading 48 of 127\n",
      "Reading 49 of 127\n",
      "Reading 50 of 127\n",
      "Reading 51 of 127\n",
      "Reading 52 of 127\n",
      "Reading 53 of 127\n",
      "Reading 54 of 127\n",
      "Reading 55 of 127\n",
      "Reading 56 of 127\n",
      "Reading 57 of 127\n",
      "Reading 58 of 127\n",
      "Reading 59 of 127\n",
      "Reading 60 of 127\n",
      "Reading 61 of 127\n",
      "Reading 62 of 127\n",
      "Reading 63 of 127\n",
      "Reading 64 of 127\n",
      "Reading 65 of 127\n",
      "Reading 66 of 127\n",
      "Reading 67 of 127\n",
      "Reading 68 of 127\n",
      "Reading 69 of 127\n",
      "Reading 70 of 127\n",
      "Reading 71 of 127\n",
      "Reading 72 of 127\n",
      "Reading 73 of 127\n",
      "Reading 74 of 127\n",
      "Reading 75 of 127\n",
      "Reading 76 of 127\n",
      "Reading 77 of 127\n",
      "Reading 78 of 127\n",
      "Reading 79 of 127\n",
      "Reading 80 of 127\n",
      "Reading 81 of 127\n",
      "Reading 82 of 127\n",
      "Reading 83 of 127\n",
      "Reading 84 of 127\n",
      "Reading 85 of 127\n",
      "Reading 86 of 127\n",
      "Reading 87 of 127\n",
      "Reading 88 of 127\n",
      "Reading 89 of 127\n",
      "Reading 90 of 127\n",
      "Reading 91 of 127\n",
      "Reading 92 of 127\n",
      "Reading 93 of 127\n",
      "Reading 94 of 127\n",
      "Reading 95 of 127\n",
      "Reading 96 of 127\n",
      "Reading 97 of 127\n",
      "Reading 98 of 127\n",
      "Reading 99 of 127\n",
      "Reading 100 of 127\n",
      "Reading 101 of 127\n",
      "Reading 102 of 127\n",
      "Reading 103 of 127\n",
      "Reading 104 of 127\n",
      "Reading 105 of 127\n",
      "Reading 106 of 127\n",
      "Reading 107 of 127\n",
      "Reading 108 of 127\n",
      "Reading 109 of 127\n",
      "Reading 110 of 127\n",
      "Reading 111 of 127\n",
      "Reading 112 of 127\n",
      "Reading 113 of 127\n",
      "Reading 114 of 127\n",
      "Reading 115 of 127\n",
      "Reading 116 of 127\n",
      "Reading 117 of 127\n",
      "Reading 118 of 127\n",
      "Reading 119 of 127\n",
      "Reading 120 of 127\n",
      "Reading 121 of 127\n",
      "Reading 122 of 127\n",
      "Reading 123 of 127\n",
      "Reading 124 of 127\n",
      "Reading 125 of 127\n",
      "Reading 126 of 127\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading Female  images ...\")\n",
    "for i, sub in enumerate(sub2):\n",
    "    print(\"Reading {} of {}\\r\".format(i, len(sub2)))\n",
    "    face_vectors = face_vector(read_image(sub))\n",
    "    if face_vectors is None:\n",
    "        continue\n",
    "    vectors.append(dlib.vector(face_vectors))\n",
    "    labels.append(female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dlib.vectors"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = np.array(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233, 128)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vec\n",
    "y = lab.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233, 128)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.append(X,y,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('face_vectors.csv',dataset,delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = KNeighborsClassifier(n_neighbors=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/praveen/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn.fit(x_train, y_train) # training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = model_knn.predict(x_test) # we use this for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_knn = confusion_matrix(y_test, y_pred_knn) # confusion matrix\n",
    "\n",
    "\n",
    "cr_knn = classification_report(y_test, y_pred_knn) # classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEICAYAAACpqsStAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADzJJREFUeJzt3X2wXHV5wPHvE2KAkEAiLwECAgETIVUcB5BKqVhBoMLEQUrRKkipAR2kHZhRIG0j2og4aoVCeRERCg1BnVKhqKF1BikvtQmtUmMAo4HmJhFCSAgmEPPy9I89SZfL5uYmkGye3O9nhpm755w953c24XvP/s4uRGYiSappULcHIEnafEZckgoz4pJUmBGXpMKMuCQVZsQlqTAjLr1GETErIo7r57ZPRcTxG1h3XET0vK6D03bPiAt4dVwi4syIWBIR7+6w7XERkRFxba/lD0bEx7bCcPstIu6PiD/rY/2Bzbnc22v57RHx2f4cIzPHZ+b9r22k0uYx4nqViDgbuBZ4f2b+aAObLQfOiogDt8J4Bm/pYwBHR8QxW+E4XRct/ru/nfAPUq8QEROBrwAnZubDfWy6FLgFmNzHvv40ImY3V/TTI+KAtnVXRcS8iFgWEY9GxLFt6z4bEd9proaXAR+LiEERcUlE/DIiFkfEtyLijc32OzXbLo6IpRExIyJGRcQU4Fjgmoj4TURc08f5fAn4mz7O5ZSI+Emz/4cj4m1t69a/i4mInSPi1uacZ0fEpztMkbw9Ih6LiBci4s6I2KnXsS6LiOea/f5J2/LdIuIfImJRRDwdEX+5LsbNa3Z727br3mEMbh7fHxFTIuIhYAUwpo/XQoUYcbX7BPB54L2ZObMf208BPhgR43qviIgPAJcBpwF7Av8O3NG2yQzg7cAbganAt3vFbALwHWAE8I/AhcAHgHcD+wJLaL1bADgb2A3YH9gdOB94KTMnNce9IDOHZeYFfZzLtcDYTvPVEfEO4GbgvGb/NwB3R8SOHfYzGTiQViRPAD7SYZszgJOAg4C3AR9rW7c3sAcwujmvG9te379rznNM8zqcBZzTxzn19lFgIjAceHoTnqdtmBFXuxOA/wD+pz8bZ+avgeuBz3VYfR5wRWbOzszVwBdoXYEe0Dz39sxcnJmrM/MrwI5A+y+DRzLznzNzbWa+1OxvUmb2ZOZK4LPA6c2V5ipacT0kM9dk5qOZuWwTz/1lWr+UOl2Nfxy4ITN/3Oz/VmAlcHSHbc8AvpCZSzKzB7i6wzZXZ+aCzHweuIfWL7N2f5WZK5uprHuBMyJiB+CPgUsz88XMfIrWO6aPbsI53pKZs5rXfNUmPE/bMCOuducDY4GbIiL6+ZwrgRMj4vBeyw8ArmqmH5YCzwNB6wqTiLi4mW54oVm/G60r0HXmddjfXW37mw2sAUYBtwHTgWkRsSAivhQRb+jvSbf5OjAqIk7tcOyL1x27Of7+tN4R9LZvr7H3Pg+AX7f9vAIY1vZ4SWYub3v8dLPPPYAhvPIK+mma17OfOo1FxRlxtXsWeC+teeS/788TMnMx8DVa0zDt5gHnZeaItn92zsyHm/nvz9C6ah2ZmSOAF2hFfv2uO+zv5F772ykz52fmqsy8PDMPA94FnEJrqqHTfvo6l1XA5c25tI9lHjCl17GHZuYdHXazENiv7fH+/T1+Y2RE7NL2+E3AAuA5Wu84Dui1bn7z83JgaNu6vTvs2/9k6XbIiOsVMnMB8AfASRHxt/182ldpxfPQtmXXA5dGxHhYf1Puj5p1w4HVwCJgcET8NbDrRo5xPTBl3XRMROwZEROan98TEW9tphyW0YrdmuZ5z7BpN/FuozW1c1Lbsq8D50fEO5tPduwSEe+PiOEdnv+t5rxHRsRooK95+A25PCKGNL/sTgG+nZlrmn1PiYjhzetwEbDuZuZPgN+PiDdFxG7ApZtxXBVkxPUqmTmPVshPj4gr+rH9Mlqf7nhj27K7aE21TGs+YfIz4ORm9XTg+8CTtKYEXmbjb/WvAu4G7ouIF2nN3b+zWbc3rZugy2hNs/yI/4/bVc15LImITvPTvc9lDa2bk+3nMpPWvPg1tG6ozuGVNyPbfQ7oAeYC/9aMa+XGjtvm180xFtC6oXt+Zj7erPsUrSvuXwEP0rohfHMzxn8F7gQeAx4F/mUTjqnCwv8phLTlRMQngDMz81VfmpJeD16JS6+jiNgnIo5pPtc+DrgYuKvb49L2a2t8E04aSIbQ+hz5QbS+EDWNft4kljaH0ymSVJjTKZJU2BafTrlu5nle6mub9Ml7N76N1C05+YZ+feHOK3FJKsyIS1JhRlySCjPiklSYEZekwoy4JBVmxCWpMCMuSYUZcUkqzIhLUmFGXJIKM+KSVJgRl6TCjLgkFWbEJakwIy5JhRlxSSrMiEtSYUZckgoz4pJUmBGXpMKMuCQVZsQlqTAjLkmFGXFJKsyIS1JhRlySCjPiklSYEZekwoy4JBVmxCWpMCMuSYUZcUkqzIhLUmFGXJIKM+KSVJgRl6TCjLgkFWbEJakwIy5JhRlxSSrMiEtSYUZckgoz4pJUmBGXpMKMuCQVZsQlqTAjLkmFGXFJKsyIS1Jhg7s9AG3YfTc+ztz/XszQXd/AR688CoB7r57FkoUrAFi5YjU7Dh3MR644spvDlDjx4PFcddIZ7DBoEDf914Nc+dD0bg9pwDDi27DDjt2bt58wmunXz16/7P0Xjl//8wO3z2HIUP8I1V2DIrj2Dz/ECbd9jZ5lS5jx8Uu5+4nHmP3cwm4PbUDY6HRKRLwlIj4TEVdHxFXNz4dujcENdPsdOoIdh3WOdGby5I8XMe5de23lUUmvdNTog5jz/LPMXfocq9auYdqsmUx4y+HdHtaA0WfEI+IzwDQggP8EZjQ/3xERl2z54WlD5j/+AkN3ewMj9x7a7aFogBs9fATzli1Z/7hn2RJGDx/RxRENLBt7L34uMD4zV7UvjIivArOAL3Z6UkRMBCYCfPjSY/m907xwf7098cizjPvdUd0ehkTEq5fl1h/GgLWx6ZS1wL4dlu/TrOsoM2/MzCMy8wgD/vpbu2Ytv5yxiLFH79ntoUj0LFvK/ruOXP94v11HsuDFpV0c0cCysSvxvwB+GBG/AOY1y94EHAJcsCUHpg37358tYeS+Qxm++07dHorEjPlP8ebd9+LAEbszf9lSzhx/BB/+p290e1gDRp8Rz8wfRMRY4ChgNK358B5gRmau2QrjG9C+d83P6Zm9lJdfXMVNFzzM0acfxO8ct08zleINTW0b1uRaLvjeNKZ/5M/ZIQZx808e4ueL/GTK1hKZW3b26rqZ5zk9pm3SJ+/t9gikDcvJN3S42/BqfmNTkgoz4pJUmBGXpMKMuCQVZsQlqTAjLkmFGXFJKsyIS1JhRlySCjPiklSYEZekwoy4JBVmxCWpMCMuSYUZcUkqzIhLUmFGXJIKM+KSVJgRl6TCjLgkFWbEJakwIy5JhRlxSSrMiEtSYUZckgoz4pJUmBGXpMKMuCQVZsQlqTAjLkmFGXFJKsyIS1JhRlySCjPiklSYEZekwoy4JBVmxCWpMCMuSYUZcUkqzIhLUmFGXJIKM+KSVJgRl6TCjLgkFWbEJakwIy5JhRlxSSrMiEtSYUZckgobvKUPcNH0LX0EafPk5G6PQHrtvBKXpMKMuCQVZsQlqTAjLkmFGXFJKsyIS1JhRlySCjPiklSYEZekwoy4JBVmxCWpMCMuSYUZcUkqzIhLUmFGXJIKM+KSVJgRl6TCjLgkFWbEJakwIy5JhRlxSSrMiEtSYUZckgoz4pJUmBGXpMKMuCQVZsQlqTAjLkmFGXFJKsyIS1JhRlySCjPiklSYEZekwoy4JBVmxCWpMCMuSYUZcUkqzIhLUmFGXJIKM+KSVJgRl6TCjLgkFWbEJakwIy5JhRlxSSrMiEtSYUZckgoz4pJUmBGXpMIGd3sA6p/rTzmLkw95K4uWv8gRX/9ct4ejAW7hwpf59Kcf57nnfsugQXDGGfty9tn78fjjv2Hy5CdZsWINo0fvxJe/fCjDhpmZLckr8SJu++kjTJh2dbeHIQGwww7BJZcczPe/fxR33vkOpk6dz5w5y5k06QkuvngM99xzJMcfvwc33TSv20Pd7hnxIh6a9wuef2lFt4chAbDXXjsyfvxwAIYNG8yYMUN55pmVzJ27giOP3A2AY44ZyX33LermMAcEIy7pNenpeYnZs3/D4Yfvytixu/DDHy4G4Ac/WMTChSu7PLrt32ZHPCLO6WPdxIiYGREzV8+YvbmHkLSNW758NRdeOIvLLjuEYcMGM2XKOKZOnc9pp81k+fI1DBkS3R7idu+13HG4HPhmpxWZeSNwI8DOU87L13AMSduoVavWcuGFszj11FG87317AnDwwbtw882HAzB37gruv39xN4c4IPQZ8Yh4bEOrgFGv/3AkVZCZTJr0BGPGDOWcc/Zfv3zx4t+y++5DWLs2ue66pznzzH27OMqBYWNX4qOAE4ElvZYH8PAWGZE6uvUD53LsAePYY+dhzPnUF/n8A/dw608f6vawNEA9+ugLfPe7zzB27C5MmDADgIsuGsNTT73E1KnzATjhhD344Af37uYwB4TI3PBsR0R8A/hmZj7YYd3UzPzwxg7gdIq2VS9N6vYIpL7c0K8bCn1eiWfmuX2s22jAJUlblh8xlKTCjLgkFWbEJakwIy5JhRlxSSrMiEtSYUZckgoz4pJUmBGXpMKMuCQVZsQlqTAjLkmFGXFJKsyIS1JhRlySCjPiklSYEZekwoy4JBVmxCWpMCMuSYUZcUkqzIhLUmFGXJIKM+KSVJgRl6TCjLgkFWbEJakwIy5JhRlxSSrMiEtSYUZckgoz4pJUmBGXpMKMuCQVZsQlqTAjLkmFGXFJKsyIS1JhRlySCjPiklSYEZekwoy4JBVmxCWpMCMuSYUZcUkqzIhLUmFGXJIKM+KSVJgRl6TCIjO7PQZtgoiYmJk3dnscUm/+3ewOr8TrmdjtAUgb4N/NLjDiklSYEZekwox4Pc45alvl380u8MamJBXmlbgkFWbEJakwI15ERJwUEU9ExJyIuKTb45HWiYibI+LZiPhZt8cyEBnxAiJiB+Ba4GTgMOBDEXFYd0clrXcLcFK3BzFQGfEajgLmZOavMvO3wDRgQpfHJAGQmQ8Az3d7HAOVEa9hNDCv7XFPs0zSAGfEa4gOy/xsqCQjXkQPsH/b4/2ABV0ai6RtiBGvYQbw5og4KCKGAGcCd3d5TJK2AUa8gMxcDVwATAdmA9/KzFndHZXUEhF3AI8A4yKiJyLO7faYBhK/di9JhXklLkmFGXFJKsyIS1JhRlySCjPiklSYEZekwoy4JBX2f04Gh3IXrEXmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm_knn,annot=True,cbar=None,cmap = 'summer')\n",
    "plt.title('K Nearest Neighbour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================KNearest Neighbour====================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97        17\n",
      "         1.0       1.00      0.97      0.98        30\n",
      "\n",
      "   micro avg       0.98      0.98      0.98        47\n",
      "   macro avg       0.97      0.98      0.98        47\n",
      "weighted avg       0.98      0.98      0.98        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('='*20+'KNearest Neighbour'+'='*20)\n",
    "print(cr_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender_class_1.pkl']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model_knn,'gender_class_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
